{"cells":[{"cell_type":"markdown","metadata":{"id":"qqZcaFU0K_ov"},"source":["Tutorials for course ECE1508 Reinforcement Learning at the University of Toronto.\n","\n","Author: Xiaocan (Bruce) Li\n","\n","Email: hsiaotsan.li@mail.utoronto.ca\n","\n","#Recap of last tutorial\n","In the previous tutorial, we covered how to build Actor-Critic algorithm based on Policy Gradient with Advantage. However, the learning process has very unstable when the policy is updated drastically.\n","\n","**Issues with Actor-Critic algorithm:**\n","\n","Small differences in parameter $\\theta$ can have very large differences in policies â€” so a single bad step can collapse the policy performance.\n","\n","\n","#Overview\n","\n","In this tutorial, we are going to improve the Actor-Critic algorithm by limiting the difference between new and old policies being too large, i.e., the Trust Region Policy Optimization (TRPO) algorithm.\n","\n","\n","**Related links:**\n","* TRPO algorithm in OpenAI: https://spinningup.openai.com/en/latest/algorithms/trpo.html\n","* TRPO algorithm paper: https://arxiv.org/pdf/1502.05477\n","* Credit to TRPO code: https://github.com/Khrylx/PyTorch-RL/blob/master/core/trpo.py\n","* Mountain Car Continuous Official Website: https://www.gymlibrary.dev/environments/classic_control/mountain_car/\n","* OpenAI Leaderboard for Most Games: https://github.com/openai/gym/wiki/Leaderboard#mountaincar-v0"]},{"cell_type":"markdown","metadata":{"id":"4YQhOnJAPdPU"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":27545,"status":"ok","timestamp":1721839197864,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"},"user_tz":240},"id":"O348rMfPrGAn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.distributions import Normal\n","import scipy\n","import torch.autograd as autograd\n","from torch.utils.tensorboard import SummaryWriter\n","import torch.optim as optim\n","\n","import os\n","import pickle\n","import click\n","import gym\n","import numpy as np\n","import math\n","import multiprocessing\n","import time\n","import matplotlib.pyplot as plt\n","\n","\n","import warnings\n","\n","# Ignore DeprecationWarning within the gym library\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"gym.*\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33817,"status":"ok","timestamp":1721839231666,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"},"user_tz":240},"id":"dOqQ50JdZKuz","outputId":"ed6491cd-2bef-46b1-d0c6-d59032b7f8d1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"," learned_models  'Tutorial 4 - Trust Region Policy Optimization, TRPO.ipynb'\n"]}],"source":["# Load files from google drive\n","# Only run this code if you run this notebook on *Google Colab* to save your training results.\n","# You can skip this code block if you run elsewhere.\n","if True:\n","  import os\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  os.chdir('/content/drive/MyDrive/Projects/ECE1508_RL/Tutorial4_TRPO')\n","  !ls"]},{"cell_type":"markdown","source":["# Utilities"],"metadata":{"id":"o36FcXT2xCFv"}},{"cell_type":"code","source":["# Math related utilities\n","def normal_entropy(std):\n","    var = std.pow(2)\n","    entropy = 0.5 + 0.5 * torch.log(2 * var * math.pi)\n","    return entropy.sum(1, keepdim=True)\n","\n","\n","def normal_log_density(x, mean, log_std, std):\n","    var = std.pow(2)\n","    log_density = -(x - mean).pow(2) / (2 * var) - 0.5 * math.log(2 * math.pi) - log_std\n","    return log_density.sum(1, keepdim=True)\n","\n","# Path related utilities\n","def check_path(path):\n","    if not os.path.exists(path):\n","        print(f\"{path} not exist\")\n","        os.makedirs(path)\n","        print(f\"Create {path} success\")\n","\n","# PyTorch related utilities\n","tensor = torch.tensor\n","DoubleTensor = torch.DoubleTensor\n","FloatTensor = torch.FloatTensor\n","LongTensor = torch.LongTensor\n","ByteTensor = torch.ByteTensor\n","ones = torch.ones\n","zeros = torch.zeros\n","\n","\n","def to_device(device, *args):\n","    return [x.to(device) for x in args]\n","\n","\n","def get_flat_params_from(model):\n","    params = []\n","    for param in model.parameters():\n","        params.append(param.view(-1))\n","\n","    flat_params = torch.cat(params)\n","    return flat_params\n","\n","\n","def set_flat_params_to(model, flat_params):\n","    prev_ind = 0\n","    for param in model.parameters():\n","        flat_size = int(np.prod(list(param.size())))\n","        param.data.copy_(\n","            flat_params[prev_ind:prev_ind + flat_size].view(param.size()))\n","        prev_ind += flat_size\n","\n","\n","def get_flat_grad_from(inputs, grad_grad=False):\n","    grads = []\n","    for param in inputs:\n","        if grad_grad:\n","            grads.append(param.grad.grad.view(-1))\n","        else:\n","            if param.grad is None:\n","                grads.append(zeros(param.view(-1).shape))\n","            else:\n","                grads.append(param.grad.view(-1))\n","\n","    flat_grad = torch.cat(grads)\n","    return flat_grad\n","\n","\n","def compute_flat_grad(output, inputs, filter_input_ids=set(), retain_graph=False, create_graph=False):\n","    if create_graph:\n","        retain_graph = True\n","\n","    inputs = list(inputs)\n","    params = []\n","    for i, param in enumerate(inputs):\n","        if i not in filter_input_ids:\n","            params.append(param)\n","\n","    grads = torch.autograd.grad(output, params, retain_graph=retain_graph, create_graph=create_graph)\n","\n","    j = 0\n","    out_grads = []\n","    for i, param in enumerate(inputs):\n","        if i in filter_input_ids:\n","            out_grads.append(zeros(param.view(-1).shape, device=param.device, dtype=param.dtype))\n","        else:\n","            out_grads.append(grads[j].view(-1))\n","            j += 1\n","    grads = torch.cat(out_grads)\n","\n","    for param in params:\n","        param.grad = None\n","    return grads\n","\n","\n","\n","# ZFilter related utilities\n","# from https://github.com/joschu/modular_rl\n","# http://www.johndcook.com/blog/standard_deviation/\n","class RunningStat(object):\n","    def __init__(self, shape):\n","        self._n = 0\n","        self._M = np.zeros(shape)\n","        self._S = np.zeros(shape)\n","\n","    def push(self, x):\n","        x = np.asarray(x)\n","        assert x.shape == self._M.shape, \"shape mismatch, expected %s, got %s\" % (self._M.shape, x.shape)\n","        self._n += 1\n","        if self._n == 1:\n","            self._M[...] = x\n","        else:\n","            oldM = self._M.copy()\n","            self._M[...] = oldM + (x - oldM) / self._n\n","            self._S[...] = self._S + (x - oldM) * (x - self._M)\n","\n","    @property\n","    def n(self):\n","        return self._n\n","\n","    @property\n","    def mean(self):\n","        return self._M\n","\n","    @property\n","    def var(self):\n","        return self._S / (self._n - 1) if self._n > 1 else np.square(self._M)\n","\n","    @property\n","    def std(self):\n","        return np.sqrt(self.var)\n","\n","    @property\n","    def shape(self):\n","        return self._M.shape\n","\n","\n","class ZFilter:\n","    \"\"\"\n","    y = (x-mean)/std\n","    using running estimates of mean,std\n","    \"\"\"\n","\n","    def __init__(self, shape, demean=True, destd=True, clip=10.0):\n","        self.demean = demean\n","        self.destd = destd\n","        self.clip = clip\n","\n","        self.rs = RunningStat(shape)\n","        self.fix = False\n","\n","    def __call__(self, x, update=True):\n","        if update and not self.fix:\n","            self.rs.push(x)\n","        if self.demean:\n","            x = x - self.rs.mean\n","        if self.destd:\n","            x = x / (self.rs.std + 1e-8)\n","        if self.clip:\n","            x = np.clip(x, -self.clip, self.clip)\n","        return x\n"],"metadata":{"id":"yuz3t1EmxBPs","executionInfo":{"status":"ok","timestamp":1721839410545,"user_tz":240,"elapsed":292,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Policy Networks"],"metadata":{"id":"N4l0rIKMwqHd"}},{"cell_type":"code","source":["# For continuous action space\n","class Policy(nn.Module):\n","    def __init__(self, state_dim, action_dim, hidden_size=(128, 128), activation='tanh', log_std=0):\n","        super().__init__()\n","        self.is_disc_action = False\n","        if activation == 'tanh':\n","            self.activation = torch.tanh\n","        elif activation == 'relu':\n","            self.activation = torch.relu\n","        elif activation == 'sigmoid':\n","            self.activation = torch.sigmoid\n","\n","        self.affine_layers = nn.ModuleList()\n","        last_dim = state_dim\n","        for nh in hidden_size:\n","            self.affine_layers.append(nn.Linear(last_dim, nh))\n","            last_dim = nh\n","\n","        self.action_mean = nn.Linear(last_dim, action_dim)\n","        self.action_mean.weight.data.mul_(0.1)\n","        self.action_mean.bias.data.mul_(0.0)\n","\n","        self.action_log_std = nn.Parameter(torch.ones(1, action_dim) * log_std)\n","\n","    def forward(self, x):\n","        for affine in self.affine_layers:\n","            x = self.activation(affine(x))\n","\n","        action_mean = self.action_mean(x)\n","        action_log_std = self.action_log_std.expand_as(action_mean)\n","        action_std = torch.exp(action_log_std)\n","\n","        return action_mean, action_log_std, action_std\n","\n","    def select_action(self, x):\n","        action_mean, _, action_std = self.forward(x)\n","        action = torch.normal(action_mean, action_std)\n","        return action\n","\n","    # Compute KL Divergence for two gaussian distributions\n","    def get_kl(self, x):\n","        mean1, log_std1, std1 = self.forward(x)\n","\n","        mean0 = mean1.detach()\n","        log_std0 = log_std1.detach()\n","        std0 = std1.detach()\n","        kl = log_std1 - log_std0 + (std0.pow(2) + (mean0 - mean1).pow(2)) / (2.0 * std1.pow(2)) - 0.5\n","        return kl.sum(1, keepdim=True)\n","\n","    def get_log_prob(self, x, actions):\n","        action_mean, action_log_std, action_std = self.forward(x)\n","        return normal_log_density(actions, action_mean, action_log_std, action_std)\n","\n","\n","    # Get Fisher Information Matrix\n","    def get_fim(self, x):\n","        mean, _, _ = self.forward(x)\n","        cov_inv = self.action_log_std.exp().pow(-2).squeeze(0).repeat(x.size(0))\n","        param_count = 0\n","        std_index = 0\n","        id = 0\n","        for name, param in self.named_parameters():\n","            if name == \"action_log_std\":\n","                std_id = id\n","                std_index = param_count\n","            param_count += param.view(-1).shape[0]\n","            id += 1\n","        return cov_inv.detach(), mean, {'std_id': std_id, 'std_index': std_index}\n","\n","\n","# For discrete action space\n","class DiscretePolicy(nn.Module):\n","    def __init__(self, state_dim, action_num, hidden_size=(128, 128), activation='tanh'):\n","        super().__init__()\n","        self.is_disc_action = True\n","        if activation == 'tanh':\n","            self.activation = torch.tanh\n","        elif activation == 'relu':\n","            self.activation = torch.relu\n","        elif activation == 'sigmoid':\n","            self.activation = torch.sigmoid\n","\n","        self.affine_layers = nn.ModuleList()\n","        last_dim = state_dim\n","        for nh in hidden_size:\n","            self.affine_layers.append(nn.Linear(last_dim, nh))\n","            last_dim = nh\n","\n","        self.action_head = nn.Linear(last_dim, action_num)\n","        self.action_head.weight.data.mul_(0.1)\n","        self.action_head.bias.data.mul_(0.0)\n","\n","    def forward(self, x):\n","        for affine in self.affine_layers:\n","            x = self.activation(affine(x))\n","\n","        action_prob = torch.softmax(self.action_head(x), dim=1)\n","        return action_prob\n","\n","    def select_action(self, x):\n","        action_prob = self.forward(x)\n","        action = action_prob.multinomial(1)\n","        return action\n","\n","    def get_kl(self, x):\n","        action_prob1 = self.forward(x)\n","        action_prob0 = action_prob1.detach()\n","        kl = action_prob0 * (torch.log(action_prob0) - torch.log(action_prob1))\n","        return kl.sum(1, keepdim=True)\n","\n","    def get_log_prob(self, x, actions):\n","        action_prob = self.forward(x)\n","        return torch.log(action_prob.gather(1, actions.long().unsqueeze(1)))\n","\n","    def get_fim(self, x):\n","        action_prob = self.forward(x)\n","        M = action_prob.pow(-1).view(-1).detach()\n","        return M, action_prob, {}\n","\n"],"metadata":{"id":"5Y3waLEVwFEP","executionInfo":{"status":"ok","timestamp":1721839235507,"user_tz":240,"elapsed":4,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Value Network"],"metadata":{"id":"Q8UIbVW9wuJ8"}},{"cell_type":"code","source":["class Value(nn.Module):\n","    def __init__(self, state_dim, hidden_size=(128, 128), activation='tanh'):\n","        super().__init__()\n","        if activation == 'tanh':\n","            self.activation = torch.tanh\n","        elif activation == 'relu':\n","            self.activation = torch.relu\n","        elif activation == 'sigmoid':\n","            self.activation = torch.sigmoid\n","\n","        self.affine_layers = nn.ModuleList()\n","        last_dim = state_dim\n","        for nh in hidden_size:\n","            self.affine_layers.append(nn.Linear(last_dim, nh))\n","            last_dim = nh\n","\n","        self.value_head = nn.Linear(last_dim, 1)\n","        self.value_head.weight.data.mul_(0.1)\n","        self.value_head.bias.data.mul_(0.0)\n","\n","    def forward(self, x):\n","        for affine in self.affine_layers:\n","            x = self.activation(affine(x))\n","\n","        value = self.value_head(x)\n","        return value"],"metadata":{"id":"wuwXH-yowxIo","executionInfo":{"status":"ok","timestamp":1721839236199,"user_tz":240,"elapsed":4,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Memory class"],"metadata":{"id":"pWw-TFICxUaM"}},{"cell_type":"code","source":["from collections import namedtuple\n","import random\n","\n","Transition = namedtuple('Transition', ('state', 'action', 'mask', 'next_state',\n","                                       'reward'))\n","\n","\n","class Memory(object):\n","    def __init__(self):\n","        self.memory = []\n","\n","    def push(self, *args):\n","        \"\"\"Saves a transition.\"\"\"\n","        self.memory.append(Transition(*args))\n","\n","    def sample(self, batch_size=None):\n","        if batch_size is None:\n","            return Transition(*zip(*self.memory))\n","        else:\n","            random_batch = random.sample(self.memory, batch_size)\n","            return Transition(*zip(*random_batch))\n","\n","    def append(self, new_memory):\n","        self.memory += new_memory.memory\n","\n","    def __len__(self):\n","        return len(self.memory)\n"],"metadata":{"id":"OkCARCnMxWYt","executionInfo":{"status":"ok","timestamp":1721839236628,"user_tz":240,"elapsed":189,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Sample Collector"],"metadata":{"id":"yjhWeXzFy5Uy"}},{"cell_type":"code","source":["def collect_samples(pid, queue, env, policy, custom_reward,\n","                    mean_action, render, running_state, min_batch_size):\n","    if pid > 0:\n","        torch.manual_seed(torch.randint(0, 5000, (1,)) * pid)\n","        if hasattr(env, 'np_random'):\n","            env.np_random.seed(env.np_random.randint(5000) * pid)\n","        if hasattr(env, 'env') and hasattr(env.env, 'np_random'):\n","            env.env.np_random.seed(env.env.np_random.randint(5000) * pid)\n","    log = dict()\n","    memory = Memory()\n","    num_steps = 0\n","    total_reward = 0\n","    min_reward = 1e6\n","    max_reward = -1e6\n","    total_c_reward = 0\n","    min_c_reward = 1e6\n","    max_c_reward = -1e6\n","    num_episodes = 0\n","\n","    while num_steps < min_batch_size:\n","        state = env.reset()\n","        if running_state is not None:\n","            state = running_state(state)\n","        reward_episode = 0\n","\n","        for t in range(10000):\n","            state_var = tensor(state).unsqueeze(0)\n","            with torch.no_grad():\n","                # If in evaluation mode, turn off exploration by using mean action.\n","                if mean_action:\n","                    if policy_net.is_disc_action:\n","                        # Discrete action takes the action with max probability\n","                        action_prob = policy_net(state_var).cpu().numpy()\n","                        action = np.argmax(action_prob)\n","                    else:\n","                        # Discrete action takes the mean of action distribution\n","                        action_mean, _, _ = policy_net(state_var)\n","                        action = action_mean.cpu().numpy()\n","                else:\n","                    action = policy.select_action(state_var)[0].numpy()\n","\n","            reward_episode += reward\n","            if running_state is not None:\n","                next_state = running_state(next_state.squeeze())\n","\n","            if custom_reward is not None:\n","                reward = custom_reward(state, action)\n","                total_c_reward += reward\n","                min_c_reward = min(min_c_reward, reward)\n","                max_c_reward = max(max_c_reward, reward)\n","\n","            mask = 0 if done else 1\n","\n","            memory.push(state, action, mask, next_state, reward)\n","\n","            if render:\n","                env.render()\n","            if done:\n","                break\n","\n","            state = next_state\n","\n","        # log stats\n","        num_steps += (t + 1)\n","        num_episodes += 1\n","        total_reward += reward_episode\n","        min_reward = min(min_reward, reward_episode)\n","        max_reward = max(max_reward, reward_episode)\n","\n","    log['num_steps'] = num_steps\n","    log['num_episodes'] = num_episodes\n","    log['total_reward'] = total_reward\n","    log['avg_reward'] = total_reward / num_episodes\n","    log['max_reward'] = max_reward\n","    log['min_reward'] = min_reward\n","    if custom_reward is not None:\n","        log['total_c_reward'] = total_c_reward\n","        log['avg_c_reward'] = total_c_reward / num_steps\n","        log['max_c_reward'] = max_c_reward\n","        log['min_c_reward'] = min_c_reward\n","\n","    if queue is not None:\n","        queue.put([pid, memory, log])\n","    else:\n","        return memory, log\n","\n","\n","def merge_log(log_list):\n","    log = dict()\n","    log['total_reward'] = sum([x['total_reward'] for x in log_list])\n","    log['num_episodes'] = sum([x['num_episodes'] for x in log_list])\n","    log['num_steps'] = sum([x['num_steps'] for x in log_list])\n","    log['avg_reward'] = log['total_reward'] / log['num_episodes']\n","    log['max_reward'] = max([x['max_reward'] for x in log_list])\n","    log['min_reward'] = min([x['min_reward'] for x in log_list])\n","    if 'total_c_reward' in log_list[0]:\n","        log['total_c_reward'] = sum([x['total_c_reward'] for x in log_list])\n","        log['avg_c_reward'] = log['total_c_reward'] / log['num_steps']\n","        log['max_c_reward'] = max([x['max_c_reward'] for x in log_list])\n","        log['min_c_reward'] = min([x['min_c_reward'] for x in log_list])\n","\n","    return log"],"metadata":{"id":"sj0zH4QrywJc","executionInfo":{"status":"ok","timestamp":1721839237983,"user_tz":240,"elapsed":190,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Estimate Advantages"],"metadata":{"id":"LywZj2FpyisK"}},{"cell_type":"code","source":["def estimate_advantages(rewards, masks, values, gamma, tau, device):\n","    rewards, masks, values = to_device(torch.device('cpu'), rewards, masks, values)\n","    tensor_type = type(rewards)\n","    deltas = tensor_type(rewards.size(0), 1)\n","    advantages = tensor_type(rewards.size(0), 1)\n","\n","    prev_value = 0\n","    prev_advantage = 0\n","    for i in reversed(range(rewards.size(0))):\n","        deltas[i] = rewards[i] + gamma * prev_value * masks[i] - values[i]\n","        advantages[i] = deltas[i] + gamma * tau * prev_advantage * masks[i]\n","\n","        prev_value = values[i, 0]\n","        prev_advantage = advantages[i, 0]\n","\n","    returns = values + advantages\n","    advantages = (advantages - advantages.mean()) / advantages.std()\n","\n","    advantages, returns = to_device(device, advantages, returns)\n","    return advantages, returns"],"metadata":{"id":"D_C85g5TyfE2","executionInfo":{"status":"ok","timestamp":1721839238961,"user_tz":240,"elapsed":4,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Conjugate Gradient"],"metadata":{"id":"N1Ie8tJ8mmtK"}},{"cell_type":"code","source":["def conjugate_gradients(Avp_f, b, nsteps, rdotr_tol=1e-10):\n","    # https://en.wikipedia.org/wiki/Conjugate_gradient_method\n","    x = zeros(b.size(), device=b.device)  # initialization approximation of x\n","    r = b.clone()  # residual\n","    p = b.clone()  # steepest descent direction\n","    rdotr = torch.dot(r, r)\n","    for i in range(nsteps):\n","        Avp = Avp_f(p)\n","        alpha = rdotr / torch.dot(p, Avp)\n","        x += alpha * p\n","        r -= alpha * Avp\n","        new_rdotr = torch.dot(r, r)\n","        betta = new_rdotr / rdotr\n","        p = r + betta * p\n","        rdotr = new_rdotr\n","        if rdotr < rdotr_tol:\n","            break\n","    return x"],"metadata":{"id":"Ln9Gje68yK71","executionInfo":{"status":"ok","timestamp":1721839240268,"user_tz":240,"elapsed":178,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Line Search"],"metadata":{"id":"75KozZ1Vmc_z"}},{"cell_type":"code","source":["def line_search(model, f, x, fullstep, expected_improve_full, max_backtracks=10, accept_ratio=0.1):\n","    fval = f(True).item()\n","\n","    for stepfrac in [.5**x for x in range(max_backtracks)]:\n","        # Compute new parameter for policy network\n","        x_new = x + stepfrac * fullstep\n","\n","        # Update policy network with new parameter\n","        set_flat_params_to(model, x_new)\n","\n","        # Compute new surrogate function value\n","        fval_new = f(True).item()\n","\n","        # Compute difference between new and old surrogate function\n","        actual_improve = fval - fval_new\n","\n","        # Compute difference under first-order approximation of surrogate function\n","        expected_improve = expected_improve_full * stepfrac\n","\n","        # Compute the ratio between actual and expected improvement of surrogate values\n","        ratio = actual_improve / expected_improve\n","\n","        # Decide whether to accept new parameter for policy network\n","        if ratio > accept_ratio:\n","            return True, x_new\n","    return False, x"],"metadata":{"id":"2UC9zcSayOw2","executionInfo":{"status":"ok","timestamp":1721839241395,"user_tz":240,"elapsed":3,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# TRPO step"],"metadata":{"id":"A7dCGpaCmL8c"}},{"cell_type":"code","source":["def trpo_step(policy_net, value_net, states, actions, returns, advantages, max_kl, damping, l2_reg, use_fim=True):\n","\n","    \"\"\"update critic\"\"\"\n","\n","    def get_value_loss(flat_params):\n","        set_flat_params_to(value_net, tensor(flat_params))\n","        for param in value_net.parameters():\n","            if param.grad is not None:\n","                param.grad.data.fill_(0)\n","        values_pred = value_net(states)\n","        value_loss = (values_pred - returns).pow(2).mean()\n","\n","        # weight decay\n","        for param in value_net.parameters():\n","            value_loss += param.pow(2).sum() * l2_reg\n","        value_loss.backward()\n","        return value_loss.item(), get_flat_grad_from(value_net.parameters()).cpu().numpy()\n","\n","    flat_params, _, opt_info = scipy.optimize.fmin_l_bfgs_b(get_value_loss,\n","                                                            get_flat_params_from(value_net).detach().cpu().numpy(),\n","                                                            maxiter=25)\n","    set_flat_params_to(value_net, tensor(flat_params))\n","\n","    \"\"\"update policy\"\"\"\n","    with torch.no_grad():\n","        fixed_log_probs = policy_net.get_log_prob(states, actions)\n","    \"\"\"define the loss function for TRPO:\n","    loss =  (-1) * Advantage*(pi_Î¸/pi_Î¸_k)\"\"\"\n","    def get_loss(volatile=False):\n","        with torch.set_grad_enabled(not volatile):\n","            log_probs = policy_net.get_log_prob(states, actions)\n","            action_loss = -advantages * torch.exp(log_probs - fixed_log_probs)\n","            return action_loss.mean()\n","\n","    \"\"\"use fisher information matrix for Hessian*vector\"\"\"\n","    def Fvp_fim(v):\n","        M, mu, info = policy_net.get_fim(states)\n","        mu = mu.view(-1)\n","        filter_input_ids = set() if policy_net.is_disc_action else set([info['std_id']])\n","\n","        t = ones(mu.size(), requires_grad=True, device=mu.device)\n","        mu_t = (mu * t).sum()\n","        Jt = compute_flat_grad(mu_t, policy_net.parameters(), filter_input_ids=filter_input_ids, create_graph=True)\n","        Jtv = (Jt * v).sum()\n","        Jv = torch.autograd.grad(Jtv, t)[0]\n","        MJv = M * Jv.detach()\n","        mu_MJv = (MJv * mu).sum()\n","        JTMJv = compute_flat_grad(mu_MJv, policy_net.parameters(), filter_input_ids=filter_input_ids).detach()\n","        JTMJv /= states.shape[0]\n","        if not policy_net.is_disc_action:\n","            std_index = info['std_index']\n","            JTMJv[std_index: std_index + M.shape[0]] += 2 * v[std_index: std_index + M.shape[0]]\n","        return JTMJv + v * damping\n","\n","    \"\"\"directly compute Hessian*vector from KL\"\"\"\n","    def Fvp_direct(v):\n","        # compute kl divergence between current policy and old policy\n","        kl = policy_net.get_kl(states)\n","        kl = kl.mean()\n","\n","        # First order gradient g_KL = â–½_{Î¸} KL\n","        grads = torch.autograd.grad(kl, policy_net.parameters(), create_graph=True)\n","        flat_grad_kl = torch.cat([grad.view(-1) for grad in grads])\n","\n","        # Inner product of g_KL and v = g_KLÂ·v\n","        kl_v = (flat_grad_kl * v).sum()\n","\n","        # gradient of g_KLÂ·v\n","        # = (gradient of g_KL) Â· v\n","        # = Hessian matrix Â· v\n","        # = HÂ·v\n","        grads = torch.autograd.grad(kl_v, policy_net.parameters())\n","        flat_grad_grad_kl = torch.cat([grad.contiguous().view(-1) for grad in grads]).detach()\n","\n","        # Return (H + dI)v instead of Hv to present ill-conditioned H.\n","        return flat_grad_grad_kl + v * damping\n","\n","    Fvp = Fvp_fim if use_fim else Fvp_direct\n","\n","    # Compute loss := (-1)*surrogate function\n","    loss = get_loss()\n","\n","    # Compute gradient of surrogate function\n","    grads = torch.autograd.grad(loss, policy_net.parameters())\n","\n","    # Flatten tensor into vector g\n","    loss_grad = torch.cat([grad.view(-1) for grad in grads]).detach()\n","\n","    # conjugate gradient solve : Hv = g for v = H^(-1)g\n","    # Compute Hv by Fvp function\n","    # stepdir is approximately H^(-1)g\n","    stepdir = conjugate_gradients(Fvp, -loss_grad, 10)\n","\n","\n","    # denominator\n","    # = g.T H^(-1) g\n","    # = g.T H^(-1).T g\n","    # = [H^(-1)g].T g\n","    # = [H^(-1)g].T HH^(-1) g\n","    # = [H^(-1)g].T H [H^(-1) g]\n","    # = stepdir.T H(stepdir)\n","    denominator = 0.5 * (stepdir.dot(Fvp(stepdir)))\n","    coeff = math.sqrt(max_kl / denominator)\n","    fullstep = stepdir * coeff\n","\n","    # Expected improve for surrogate function in first-order approximation:\n","    # L(Î¸_k, Î¸) = g.T (Î¸ - Î¸_k)\n","    # = g.T (Î¸_k + step - Î¸_k)\n","    # = g.T (step)\n","    expected_improve = -loss_grad.dot(fullstep)\n","\n","    prev_params = get_flat_params_from(policy_net)\n","\n","\n","    \"\"\"\n","    line search for step size for satisfying the KL divergence constraint\n","    \"\"\"\n","    success, new_params = line_search(policy_net, get_loss, prev_params, fullstep, expected_improve)\n","\n","\n","    set_flat_params_to(policy_net, new_params)\n","\n","    return success"],"metadata":{"id":"AhxenlKmyTnL","executionInfo":{"status":"ok","timestamp":1721839242704,"user_tz":240,"elapsed":182,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Agent"],"metadata":{"id":"ciaalvhArBf-"}},{"cell_type":"code","source":["class Agent:\n","\n","    def __init__(self, env, policy, device, custom_reward=None, running_state=None, num_threads=1):\n","        self.env = env\n","        self.policy = policy\n","        self.device = device\n","        self.custom_reward = custom_reward\n","        self.running_state = running_state\n","        self.num_threads = num_threads\n","\n","    def collect_samples(self, min_batch_size, mean_action=False, render=False):\n","        t_start = time.time()\n","        to_device(torch.device('cpu'), self.policy)\n","        thread_batch_size = int(math.floor(min_batch_size / self.num_threads))\n","        queue = multiprocessing.Queue()\n","        workers = []\n","\n","        for i in range(self.num_threads-1):\n","            worker_args = (i+1, queue, self.env, self.policy, self.custom_reward, mean_action,\n","                           False, self.running_state, thread_batch_size)\n","            workers.append(multiprocessing.Process(target=collect_samples, args=worker_args))\n","        for worker in workers:\n","            worker.start()\n","\n","        memory, log = collect_samples(0, None, self.env, self.policy, self.custom_reward, mean_action,\n","                                      render, self.running_state, thread_batch_size)\n","\n","        worker_logs = [None] * len(workers)\n","        worker_memories = [None] * len(workers)\n","        for _ in workers:\n","            pid, worker_memory, worker_log = queue.get()\n","            worker_memories[pid - 1] = worker_memory\n","            worker_logs[pid - 1] = worker_log\n","        for worker_memory in worker_memories:\n","            memory.append(worker_memory)\n","        batch = memory.sample()\n","        if self.num_threads > 1:\n","            log_list = [log] + worker_logs\n","            log = merge_log(log_list)\n","        to_device(self.device, self.policy)\n","        t_end = time.time()\n","        log['sample_time'] = t_end - t_start\n","        log['action_mean'] = np.mean(np.vstack(batch.action), axis=0)\n","        log['action_min'] = np.min(np.vstack(batch.action), axis=0)\n","        log['action_max'] = np.max(np.vstack(batch.action), axis=0)\n","        return batch, log\n"],"metadata":{"id":"jYY1fMojzGnJ","executionInfo":{"status":"ok","timestamp":1721839243956,"user_tz":240,"elapsed":276,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Train Main - MountainCar-v0"],"metadata":{"id":"yz_gfQCVqslk"}},{"cell_type":"code","source":["import argparse\n","\n","parser = argparse.ArgumentParser(description='PyTorch TRPO example')\n","parser.add_argument('--env-name', default=\"MountainCar-v0\", metavar='G',\n","                    help='name of the environment to run')\n","parser.add_argument('--model-path', metavar='G',\n","                    help='path of pre-trained model')\n","parser.add_argument('--render', action='store_true', default=False,\n","                    help='render the environment')\n","parser.add_argument('--log-std', type=float, default=-0.0, metavar='G',\n","                    help='log std for the policy (default: -0.0)')\n","parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n","                    help='discount factor (default: 0.99)')\n","parser.add_argument('--tau', type=float, default=0.95, metavar='G',\n","                    help='gae (default: 0.95)')\n","parser.add_argument('--l2-reg', type=float, default=1e-3, metavar='G',\n","                    help='l2 regularization regression (default: 1e-3)')\n","parser.add_argument('--max-kl', type=float, default=1e-2, metavar='G',\n","                    help='max kl value (default: 1e-2)')\n","parser.add_argument('--damping', type=float, default=1e-2, metavar='G',\n","                    help='damping (default: 1e-2)')\n","parser.add_argument('--num-threads', type=int, default=4, metavar='N',\n","                    help='number of threads for agent (default: 4)')\n","parser.add_argument('--seed', type=int, default=1, metavar='N',\n","                    help='random seed (default: 1)')\n","parser.add_argument('--min-batch-size', type=int, default=2048, metavar='N',\n","                    help='minimal batch size per TRPO update (default: 2048)')\n","parser.add_argument('--eval-batch-size', type=int, default=2048, metavar='N',\n","                    help='minimal batch size for evaluation (default: 2048)')\n","parser.add_argument('--max-iter-num', type=int, default=500, metavar='N',\n","                    help='maximal number of main iterations (default: 500)')\n","parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n","                    help='interval between training status logs (default: 10)')\n","parser.add_argument('--save-model-interval', type=int, default=0, metavar='N',\n","                    help=\"interval between saving model (default: 0, means don't save)\")\n","parser.add_argument('--gpu-index', type=int, default=0, metavar='N')\n","\n","args = parser.parse_args(args=[\n","    '--env-name', 'MountainCar-v0',\n","    '--render',\n","    '--log-std', '-0.0',\n","    '--gamma', '0.99',\n","    '--tau', '0.95',\n","    '--l2-reg', '1e-3',\n","    '--max-kl', '1e-2',\n","    '--damping', '1e-2',\n","    '--num-threads', '8',\n","    '--seed', '1',\n","    '--min-batch-size', '2048',\n","    '--eval-batch-size', '2048',\n","    '--max-iter-num', '50',\n","    '--log-interval', '1',\n","    '--save-model-interval', '0',\n","    '--gpu-index', '0'\n","])\n","\n","# Printing some of the parsed arguments for demonstration\n","print(\"Environment Name:\", args.env_name)\n","print(\"Model Path:\", args.model_path)\n","print(\"Render Environment:\", args.render, type(args.render))\n","print(\"Tau:\", args.tau, type(args.tau))\n","print(\"GPU Index:\", args.gpu_index, type(args.gpu_index))\n","\n","\n","\n","dtype = torch.float64\n","torch.set_default_dtype(dtype)\n","device = torch.device('cuda', index=args.gpu_index) if torch.cuda.is_available() else torch.device('cpu')\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(args.gpu_index)\n","\n","\n","\n","\"\"\"environment\"\"\"\n","env = gym.make(args.env_name)\n","state_dim = env.observation_space.shape[0]\n","is_disc_action = len(env.action_space.shape) == 0\n","running_state = ZFilter((state_dim,), clip=5)\n","# running_reward = ZFilter((1,), demean=False, clip=10)\n","\n","\"\"\"seeding\"\"\"\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","env.seed(args.seed)\n","\n","\n","\n","\"\"\"define actor and critic\"\"\"\n","if args.model_path is None:\n","    if is_disc_action:\n","        policy_net = DiscretePolicy(state_dim, env.action_space.n)\n","    else:\n","        policy_net = Policy(state_dim, env.action_space.shape[0], log_std=args.log_std)\n","    value_net = Value(state_dim)\n","else:\n","    policy_net, value_net, running_state = pickle.load(open(args.model_path, \"rb\"))\n","policy_net.to(device)\n","value_net.to(device)\n","\n","\n","\n","\"\"\"create agent\"\"\"\n","agent = Agent(env, policy_net, device, running_state=running_state, num_threads=args.num_threads)\n","\n","\n","def update_params(batch):\n","    states = torch.from_numpy(np.stack(batch.state)).to(dtype).to(device)\n","    actions = torch.from_numpy(np.stack(batch.action)).to(dtype).to(device)\n","    rewards = torch.from_numpy(np.stack(batch.reward)).to(dtype).to(device)\n","    masks = torch.from_numpy(np.stack(batch.mask)).to(dtype).to(device)\n","    with torch.no_grad():\n","        values = value_net(states)\n","\n","    \"\"\"get advantage estimation from the trajectories\"\"\"\n","    advantages, returns = estimate_advantages(rewards, masks, values, args.gamma, args.tau, device)\n","\n","    \"\"\"perform TRPO update\"\"\"\n","    trpo_step(policy_net, value_net, states, actions, returns, advantages, args.max_kl, args.damping, args.l2_reg)\n","\n","\n","def main_train():\n","    best_avg_reward = float('-inf')\n","    average_train_rewards = []\n","\n","    for i_iter in range(args.max_iter_num):\n","        \"\"\"generate multiple trajectories that reach the minimum batch_size\"\"\"\n","        batch, log = agent.collect_samples(args.min_batch_size, render=args.render)\n","        t0 = time.time()\n","        update_params(batch)\n","        t1 = time.time()\n","        \"\"\"evaluate with determinstic action (remove noise for exploration)\"\"\"\n","        _, log_eval = agent.collect_samples(args.eval_batch_size, mean_action=True)\n","        t2 = time.time()\n","\n","        average_train_rewards.append(log['avg_reward'])\n","\n","        if i_iter % args.log_interval == 0:\n","            print('{}\\tT_sample {:.4f}\\tT_update {:.4f}\\tT_eval {:.4f}\\ttrain_R_min {:.2f}\\ttrain_R_max {:.2f}\\ttrain_R_avg {:.2f}\\teval_R_avg {:.2f}'.format(\n","                i_iter, log['sample_time'], t1-t0, t2-t1, log['min_reward'], log['max_reward'], log['avg_reward'], log_eval['avg_reward']))\n","\n","        # Save best model\n","        if log['avg_reward'] > best_avg_reward:\n","            best_avg_reward = log['avg_reward']\n","            to_device(torch.device('cpu'), policy_net, value_net)\n","            check_path('learned_models')\n","            pickle.dump((policy_net, value_net, running_state),\n","                        open(os.path.join('learned_models/{}_trpo.p'.format(args.env_name)), 'wb'))\n","            print(f'New best average reward={best_avg_reward}. Model saved!')\n","            to_device(device, policy_net, value_net)\n","\n","        \"\"\"clean up gpu memory\"\"\"\n","        torch.cuda.empty_cache()\n","\n","    plt.plot(average_train_rewards)\n","    plt.xlabel('Iteration')\n","    plt.ylabel('Average Training Reward')\n","    plt.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuiSoSPmslc_","outputId":"30bedcb4-11d0-4dff-c3be-785b067a2514","executionInfo":{"status":"ok","timestamp":1721582571991,"user_tz":240,"elapsed":627,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Environment Name: MountainCar-v0\n","Model Path: None\n","Render Environment: True <class 'bool'>\n","Tau: 0.95 <class 'float'>\n","GPU Index: 0 <class 'int'>\n"]}]},{"cell_type":"code","source":["main_train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BempJIJx3Ciq","executionInfo":{"status":"ok","timestamp":1721583374072,"user_tz":240,"elapsed":801242,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}},"outputId":"78b6845b-931c-4ee4-ba63-c15ecd8b2c2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-19-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n"]},{"output_type":"stream","name":"stdout","text":["0\tT_sample 14.4602\tT_update 2.1288\tT_eval 1.0732\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","New best average reward=-200.0. Model saved!\n","1\tT_sample 13.8454\tT_update 1.8813\tT_eval 1.6868\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","2\tT_sample 14.0078\tT_update 3.6325\tT_eval 1.9655\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","3\tT_sample 14.0709\tT_update 2.2107\tT_eval 1.0644\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","4\tT_sample 13.7075\tT_update 2.0158\tT_eval 1.0826\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","5\tT_sample 13.7113\tT_update 1.9739\tT_eval 1.1113\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","6\tT_sample 13.6872\tT_update 2.0940\tT_eval 1.0959\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","7\tT_sample 14.0288\tT_update 2.3569\tT_eval 1.8452\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","8\tT_sample 13.9587\tT_update 3.6387\tT_eval 1.5266\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","10\tT_sample 13.7494\tT_update 2.2614\tT_eval 1.0895\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","11\tT_sample 13.8132\tT_update 2.1661\tT_eval 1.0786\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","12\tT_sample 13.7105\tT_update 2.0124\tT_eval 1.6904\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","13\tT_sample 14.0306\tT_update 3.0455\tT_eval 1.8226\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","14\tT_sample 14.1287\tT_update 2.2431\tT_eval 1.1040\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","15\tT_sample 13.7516\tT_update 2.0534\tT_eval 1.0876\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","16\tT_sample 13.8860\tT_update 2.0339\tT_eval 1.1062\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","17\tT_sample 13.7335\tT_update 2.0247\tT_eval 1.6188\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","18\tT_sample 14.0206\tT_update 2.8446\tT_eval 1.8635\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","19\tT_sample 14.4458\tT_update 2.0974\tT_eval 1.0822\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","20\tT_sample 13.7218\tT_update 2.0634\tT_eval 1.1092\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","21\tT_sample 13.7654\tT_update 2.0278\tT_eval 1.0914\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","22\tT_sample 13.9176\tT_update 2.4462\tT_eval 1.9290\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","23\tT_sample 14.0950\tT_update 3.5210\tT_eval 1.8453\ttrain_R_min -200.00\ttrain_R_max -200.00\ttrain_R_avg -200.00\teval_R_avg -200.00\n","24\tT_sample 14.0471\tT_update 2.0449\tT_eval 1.0775\ttrain_R_min -200.00\ttrain_R_max -171.00\ttrain_R_avg -198.19\teval_R_avg -200.00\n","New best average reward=-198.1875. Model saved!\n","25\tT_sample 13.7973\tT_update 1.9377\tT_eval 1.0817\ttrain_R_min -200.00\ttrain_R_max -172.00\ttrain_R_avg -198.25\teval_R_avg -200.00\n","26\tT_sample 13.8285\tT_update 1.8676\tT_eval 1.1086\ttrain_R_min -200.00\ttrain_R_max -164.00\ttrain_R_avg -190.94\teval_R_avg -200.00\n","New best average reward=-190.9375. Model saved!\n","27\tT_sample 13.1318\tT_update 1.7817\tT_eval 1.0787\ttrain_R_min -200.00\ttrain_R_max -156.00\ttrain_R_avg -183.88\teval_R_avg -200.00\n","New best average reward=-183.875. Model saved!\n","29\tT_sample 11.5910\tT_update 1.6492\tT_eval 1.1081\ttrain_R_min -200.00\ttrain_R_max -133.00\ttrain_R_avg -163.44\teval_R_avg -200.00\n","New best average reward=-163.4375. Model saved!\n","30\tT_sample 10.9098\tT_update 1.6444\tT_eval 1.0919\ttrain_R_min -200.00\ttrain_R_max -129.00\ttrain_R_avg -164.75\teval_R_avg -200.00\n","31\tT_sample 11.3381\tT_update 1.6054\tT_eval 1.1139\ttrain_R_min -166.00\ttrain_R_max -137.00\ttrain_R_avg -159.12\teval_R_avg -200.00\n","New best average reward=-159.125. Model saved!\n","32\tT_sample 10.5257\tT_update 1.6551\tT_eval 1.1253\ttrain_R_min -164.00\ttrain_R_max -120.00\ttrain_R_avg -143.50\teval_R_avg -200.00\n","New best average reward=-143.5. Model saved!\n","33\tT_sample 11.2179\tT_update 1.5915\tT_eval 1.0915\ttrain_R_min -200.00\ttrain_R_max -119.00\ttrain_R_avg -146.88\teval_R_avg -200.00\n","34\tT_sample 11.6504\tT_update 1.6315\tT_eval 1.0865\ttrain_R_min -174.00\ttrain_R_max -115.00\ttrain_R_avg -146.00\teval_R_avg -200.00\n","35\tT_sample 9.4849\tT_update 1.9448\tT_eval 1.1090\ttrain_R_min -166.00\ttrain_R_max -113.00\ttrain_R_avg -139.39\teval_R_avg -200.00\n","New best average reward=-139.38888888888889. Model saved!\n","36\tT_sample 9.5919\tT_update 1.7099\tT_eval 1.0670\ttrain_R_min -171.00\ttrain_R_max -93.00\ttrain_R_avg -134.00\teval_R_avg -200.00\n","New best average reward=-134.0. Model saved!\n","37\tT_sample 14.1631\tT_update 1.6990\tT_eval 1.1360\ttrain_R_min -188.00\ttrain_R_max -97.00\ttrain_R_avg -133.38\teval_R_avg -200.00\n","New best average reward=-133.38095238095238. Model saved!\n","38\tT_sample 9.8015\tT_update 1.5400\tT_eval 1.0891\ttrain_R_min -182.00\ttrain_R_max -101.00\ttrain_R_avg -130.67\teval_R_avg -200.00\n","New best average reward=-130.66666666666666. Model saved!\n","39\tT_sample 13.5861\tT_update 1.7910\tT_eval 1.0854\ttrain_R_min -166.00\ttrain_R_max -90.00\ttrain_R_avg -119.52\teval_R_avg -200.00\n","New best average reward=-119.52173913043478. Model saved!\n","40\tT_sample 11.9543\tT_update 1.7613\tT_eval 1.1078\ttrain_R_min -118.00\ttrain_R_max -99.00\ttrain_R_avg -113.50\teval_R_avg -200.00\n","New best average reward=-113.5. Model saved!\n","41\tT_sample 10.2620\tT_update 1.6396\tT_eval 1.2097\ttrain_R_min -125.00\ttrain_R_max -88.00\ttrain_R_avg -111.54\teval_R_avg -200.00\n","New best average reward=-111.54166666666667. Model saved!\n","42\tT_sample 12.1074\tT_update 1.6133\tT_eval 1.0761\ttrain_R_min -120.00\ttrain_R_max -86.00\ttrain_R_avg -109.67\teval_R_avg -200.00\n","New best average reward=-109.66666666666667. Model saved!\n","43\tT_sample 11.1386\tT_update 1.5656\tT_eval 1.0960\ttrain_R_min -118.00\ttrain_R_max -85.00\ttrain_R_avg -108.38\teval_R_avg -200.00\n","New best average reward=-108.375. Model saved!\n","44\tT_sample 10.8706\tT_update 1.8407\tT_eval 1.1045\ttrain_R_min -173.00\ttrain_R_max -85.00\ttrain_R_avg -110.04\teval_R_avg -200.00\n","45\tT_sample 11.0467\tT_update 1.6860\tT_eval 1.0758\ttrain_R_min -170.00\ttrain_R_max -86.00\ttrain_R_avg -114.38\teval_R_avg -200.00\n","46\tT_sample 11.2821\tT_update 1.6819\tT_eval 1.0996\ttrain_R_min -117.00\ttrain_R_max -85.00\ttrain_R_avg -106.12\teval_R_avg -200.00\n","New best average reward=-106.125. Model saved!\n","47\tT_sample 11.8324\tT_update 1.5845\tT_eval 1.1016\ttrain_R_min -118.00\ttrain_R_max -84.00\ttrain_R_avg -104.67\teval_R_avg -200.00\n","New best average reward=-104.66666666666667. Model saved!\n","48\tT_sample 10.0823\tT_update 1.7864\tT_eval 1.0882\ttrain_R_min -119.00\ttrain_R_max -86.00\ttrain_R_avg -105.75\teval_R_avg -200.00\n","49\tT_sample 11.1348\tT_update 1.7310\tT_eval 1.0950\ttrain_R_min -116.00\ttrain_R_max -85.00\ttrain_R_avg -105.42\teval_R_avg -200.00\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# Eval Main - MountainCar-v0"],"metadata":{"id":"_uoWUQLdoR7K"}},{"cell_type":"code","source":["import argparse\n","\n","parser = argparse.ArgumentParser(description='PyTorch TRPO example')\n","parser.add_argument('--env-name', default=\"Hopper-v2\", metavar='G',\n","                    help='name of the environment to run')\n","parser.add_argument('--model-path', metavar='G', required=True,\n","                    help='path of pre-trained model')\n","parser.add_argument('--render', action='store_true', default=False,\n","                    help='render the environment')\n","parser.add_argument('--seed', type=int, default=1, metavar='N',\n","                    help='random seed (default: 1)')\n","parser.add_argument('--gpu-index', type=int, default=0, metavar='N')\n","parser.add_argument('--num-eval', type=int, default=1, metavar='N')\n","\n","args = parser.parse_args(args=[\n","    '--env-name', 'MountainCar-v0',\n","    '--model-path', 'learned_models/MountainCar-v0_trpo.p',\n","    '--seed', '1',\n","    '--gpu-index', '0',\n","    '--num-eval', '10'\n","])\n","\n","\n","dtype = torch.float64\n","torch.set_default_dtype(dtype)\n","device = torch.device('cuda', index=args.gpu_index) if torch.cuda.is_available() else torch.device('cpu')\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(args.gpu_index)\n","\n","\"\"\"environment\"\"\"\n","env = gym.make(args.env_name)\n","state_dim = env.observation_space.shape[0]\n","is_disc_action = len(env.action_space.shape) == 0\n","running_state = ZFilter((state_dim,), clip=5)\n","\n","\"\"\"seeding\"\"\"\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","env.seed(args.seed)\n","\n","\"\"\"define actor and critic\"\"\"\n","policy_net, value_net, running_state = pickle.load(open(args.model_path, \"rb\"))\n","policy_net.to(device)\n","value_net.to(device)\n","\n","\"\"\"create agent\"\"\"\n","agent = Agent(env, policy_net, device, running_state=running_state, num_threads=1)\n","mean_action = True  # In evaluation, there is no exploration of action, just use mean action.\n","\n","\n","\n","def main_eval():\n","    episode_rewards = []\n","\n","    for e in range(1, args.num_eval+1):\n","        done = False\n","        state = env.reset()\n","        if running_state is not None:\n","            state = running_state(state.squeeze())\n","        reward_episode = 0\n","\n","        while not done:\n","            state_var = tensor(state, dtype=dtype).unsqueeze(0).to(device)\n","            with torch.no_grad():\n","              if policy_net.is_disc_action:\n","                    # Discrete action takes the action with max probability\n","                    action_prob = policy_net(state_var).cpu().numpy()\n","                    action = np.argmax(action_prob)\n","              else:\n","                    # Discrete action takes the mean of action distribution\n","                    action_mean, _, _ = policy_net(state_var)\n","                    action = action_mean.cpu().numpy()\n","            next_state, reward, done, _ = env.step(action)\n","\n","            if running_state is not None:\n","                next_state = running_state(next_state.squeeze())\n","\n","            state = next_state\n","\n","\n","            if args.render:\n","                env.render()\n","            reward_episode += reward\n","\n","\n","        print(f\"Episode {e} Total Reward {reward_episode}\")\n","        episode_rewards.append(reward_episode)\n","\n","    \"\"\"clean up gpu memory\"\"\"\n","    torch.cuda.empty_cache()\n","\n","    env.close()\n","    print(f\"Number of Episodes {args.num_eval} Mean Reward {np.mean(episode_rewards)} Std Reward {np.std(episode_rewards)}\")\n","\n","    return episode_rewards\n","\n","main_eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bbim4DIrHXnL","executionInfo":{"status":"ok","timestamp":1721839441096,"user_tz":240,"elapsed":900,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}},"outputId":"8038f658-90a7-4d40-ba31-29789cd89678"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 1 Total Reward -114.0\n","Episode 2 Total Reward -85.0\n","Episode 3 Total Reward -112.0\n","Episode 4 Total Reward -85.0\n","Episode 5 Total Reward -114.0\n","Episode 6 Total Reward -116.0\n","Episode 7 Total Reward -88.0\n","Episode 8 Total Reward -116.0\n","Episode 9 Total Reward -114.0\n","Episode 10 Total Reward -112.0\n","Number of Episodes 10 Mean Reward -105.6 Std Reward 12.91665591397402\n"]},{"output_type":"execute_result","data":{"text/plain":["[-114.0, -85.0, -112.0, -85.0, -114.0, -116.0, -88.0, -116.0, -114.0, -112.0]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# Train Main - CartPole-v0"],"metadata":{"id":"cjEWxJCzngOp"}},{"cell_type":"code","source":["import argparse\n","\n","parser = argparse.ArgumentParser(description='PyTorch TRPO example')\n","parser.add_argument('--env-name', default=\"MountainCar-v0\", metavar='G',\n","                    help='name of the environment to run')\n","parser.add_argument('--model-path', metavar='G',\n","                    help='path of pre-trained model')\n","parser.add_argument('--render', action='store_true', default=False,\n","                    help='render the environment')\n","parser.add_argument('--log-std', type=float, default=-0.0, metavar='G',\n","                    help='log std for the policy (default: -0.0)')\n","parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n","                    help='discount factor (default: 0.99)')\n","parser.add_argument('--tau', type=float, default=0.95, metavar='G',\n","                    help='gae (default: 0.95)')\n","parser.add_argument('--l2-reg', type=float, default=1e-3, metavar='G',\n","                    help='l2 regularization regression (default: 1e-3)')\n","parser.add_argument('--max-kl', type=float, default=1e-2, metavar='G',\n","                    help='max kl value (default: 1e-2)')\n","parser.add_argument('--damping', type=float, default=1e-2, metavar='G',\n","                    help='damping (default: 1e-2)')\n","parser.add_argument('--num-threads', type=int, default=4, metavar='N',\n","                    help='number of threads for agent (default: 4)')\n","parser.add_argument('--seed', type=int, default=1, metavar='N',\n","                    help='random seed (default: 1)')\n","parser.add_argument('--min-batch-size', type=int, default=2048, metavar='N',\n","                    help='minimal batch size per TRPO update (default: 2048)')\n","parser.add_argument('--eval-batch-size', type=int, default=2048, metavar='N',\n","                    help='minimal batch size for evaluation (default: 2048)')\n","parser.add_argument('--max-iter-num', type=int, default=500, metavar='N',\n","                    help='maximal number of main iterations (default: 500)')\n","parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n","                    help='interval between training status logs (default: 10)')\n","parser.add_argument('--save-model-interval', type=int, default=0, metavar='N',\n","                    help=\"interval between saving model (default: 0, means don't save)\")\n","parser.add_argument('--gpu-index', type=int, default=0, metavar='N')\n","\n","args = parser.parse_args(args=[\n","    '--env-name', 'CartPole-v0',\n","    '--render',\n","    '--log-std', '-0.0',\n","    '--gamma', '0.99',\n","    '--tau', '0.95',\n","    '--l2-reg', '1e-3',\n","    '--max-kl', '1e-2',\n","    '--damping', '1e-2',\n","    '--num-threads', '8',\n","    '--seed', '1',\n","    '--min-batch-size', '2048',\n","    '--eval-batch-size', '2048',\n","    '--max-iter-num', '50',\n","    '--log-interval', '1',\n","    '--save-model-interval', '0',\n","    '--gpu-index', '0'\n","])\n","\n","# Printing some of the parsed arguments for demonstration\n","print(\"Environment Name:\", args.env_name)\n","print(\"Model Path:\", args.model_path)\n","print(\"Render Environment:\", args.render, type(args.render))\n","print(\"Tau:\", args.tau, type(args.tau))\n","print(\"GPU Index:\", args.gpu_index, type(args.gpu_index))\n","\n","\n","\n","dtype = torch.float64\n","torch.set_default_dtype(dtype)\n","device = torch.device('cuda', index=args.gpu_index) if torch.cuda.is_available() else torch.device('cpu')\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(args.gpu_index)\n","\n","\n","\n","\"\"\"environment\"\"\"\n","env = gym.make(args.env_name)\n","state_dim = env.observation_space.shape[0]\n","is_disc_action = len(env.action_space.shape) == 0\n","running_state = ZFilter((state_dim,), clip=5)\n","# running_reward = ZFilter((1,), demean=False, clip=10)\n","\n","\"\"\"seeding\"\"\"\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","env.seed(args.seed)\n","\n","\n","\n","\"\"\"define actor and critic\"\"\"\n","if args.model_path is None:\n","    if is_disc_action:\n","        policy_net = DiscretePolicy(state_dim, env.action_space.n)\n","    else:\n","        policy_net = Policy(state_dim, env.action_space.shape[0], log_std=args.log_std)\n","    value_net = Value(state_dim)\n","else:\n","    policy_net, value_net, running_state = pickle.load(open(args.model_path, \"rb\"))\n","policy_net.to(device)\n","value_net.to(device)\n","\n","\n","\n","\"\"\"create agent\"\"\"\n","agent = Agent(env, policy_net, device, running_state=running_state, num_threads=args.num_threads)\n","\n","\n","def update_params(batch):\n","    states = torch.from_numpy(np.stack(batch.state)).to(dtype).to(device)\n","    actions = torch.from_numpy(np.stack(batch.action)).to(dtype).to(device)\n","    rewards = torch.from_numpy(np.stack(batch.reward)).to(dtype).to(device)\n","    masks = torch.from_numpy(np.stack(batch.mask)).to(dtype).to(device)\n","    with torch.no_grad():\n","        values = value_net(states)\n","\n","    \"\"\"get advantage estimation from the trajectories\"\"\"\n","    advantages, returns = estimate_advantages(rewards, masks, values, args.gamma, args.tau, device)\n","\n","    \"\"\"perform TRPO update\"\"\"\n","    trpo_step(policy_net, value_net, states, actions, returns, advantages, args.max_kl, args.damping, args.l2_reg)\n","\n","\n","def main_train():\n","    best_avg_reward = float('-inf')\n","    average_train_rewards = []\n","\n","    for i_iter in range(args.max_iter_num):\n","        \"\"\"generate multiple trajectories that reach the minimum batch_size\"\"\"\n","        batch, log = agent.collect_samples(args.min_batch_size, render=args.render)\n","        t0 = time.time()\n","        update_params(batch)\n","        t1 = time.time()\n","        \"\"\"evaluate with determinstic action (remove noise for exploration)\"\"\"\n","        _, log_eval = agent.collect_samples(args.eval_batch_size, mean_action=True)\n","        t2 = time.time()\n","\n","        average_train_rewards.append(log['avg_reward'])\n","\n","        if i_iter % args.log_interval == 0:\n","            print('{}\\tT_sample {:.4f}\\tT_update {:.4f}\\tT_eval {:.4f}\\ttrain_R_min {:.2f}\\ttrain_R_max {:.2f}\\ttrain_R_avg {:.2f}\\teval_R_avg {:.2f}'.format(\n","                i_iter, log['sample_time'], t1-t0, t2-t1, log['min_reward'], log['max_reward'], log['avg_reward'], log_eval['avg_reward']))\n","\n","        # Save best model\n","        if log['avg_reward'] > best_avg_reward:\n","            best_avg_reward = log['avg_reward']\n","            to_device(torch.device('cpu'), policy_net, value_net)\n","            check_path('learned_models')\n","            pickle.dump((policy_net, value_net, running_state),\n","                        open(os.path.join('learned_models/{}_trpo.p'.format(args.env_name)), 'wb'))\n","            print(f'New best average reward={best_avg_reward}. Model saved!')\n","            to_device(device, policy_net, value_net)\n","\n","        \"\"\"clean up gpu memory\"\"\"\n","        torch.cuda.empty_cache()\n","\n","    plt.plot(average_train_rewards)\n","    plt.xlabel('Iteration')\n","    plt.ylabel('Average Training Reward')\n","    plt.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fmnR1L2-w68","executionInfo":{"status":"ok","timestamp":1721593704399,"user_tz":240,"elapsed":183,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}},"outputId":"d2f7c66d-7b27-4bb5-b097-02d4e6a8c2b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Environment Name: CartPole-v0\n","Model Path: None\n","Render Environment: True <class 'bool'>\n","Tau: 0.95 <class 'float'>\n","GPU Index: 0 <class 'int'>\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n","  logger.warn(\n"]}]},{"cell_type":"code","source":["main_train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vbAu1hNC-7RF","executionInfo":{"status":"ok","timestamp":1721594334218,"user_tz":240,"elapsed":591205,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}},"outputId":"dbc70bc3-84fb-4151-9bd6-13d7b9639b68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n","<ipython-input-78-b6fb2253d08f>:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  action = int(action) if policy.is_disc_action else action.astype(np.float64)\n"]},{"output_type":"stream","name":"stdout","text":["0\tT_sample 6.9662\tT_update 2.2001\tT_eval 1.3505\ttrain_R_min 10.00\ttrain_R_max 48.00\ttrain_R_avg 20.58\teval_R_avg 9.32\n","New best average reward=20.58252427184466. Model saved!\n","1\tT_sample 6.1537\tT_update 1.4174\tT_eval 0.8339\ttrain_R_min 9.00\ttrain_R_max 69.00\ttrain_R_avg 24.26\teval_R_avg 9.36\n","New best average reward=24.255555555555556. Model saved!\n","2\tT_sample 6.5259\tT_update 2.3797\tT_eval 1.3120\ttrain_R_min 10.00\ttrain_R_max 108.00\ttrain_R_avg 31.69\teval_R_avg 9.43\n","New best average reward=31.690140845070424. Model saved!\n","3\tT_sample 6.8312\tT_update 1.3727\tT_eval 0.8257\ttrain_R_min 11.00\ttrain_R_max 137.00\ttrain_R_avg 49.64\teval_R_avg 9.30\n","New best average reward=49.644444444444446. Model saved!\n","4\tT_sample 8.4459\tT_update 1.7972\tT_eval 0.8226\ttrain_R_min 17.00\ttrain_R_max 200.00\ttrain_R_avg 103.35\teval_R_avg 9.44\n","New best average reward=103.34615384615384. Model saved!\n","5\tT_sample 7.9421\tT_update 1.9472\tT_eval 0.8011\ttrain_R_min 39.00\ttrain_R_max 200.00\ttrain_R_avg 156.00\teval_R_avg 9.33\n","New best average reward=156.0. Model saved!\n","6\tT_sample 8.1033\tT_update 2.8892\tT_eval 1.3873\ttrain_R_min 61.00\ttrain_R_max 200.00\ttrain_R_avg 182.50\teval_R_avg 9.28\n","New best average reward=182.5. Model saved!\n","7\tT_sample 8.7392\tT_update 2.3456\tT_eval 1.3718\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.37\n","New best average reward=200.0. Model saved!\n","8\tT_sample 9.2268\tT_update 2.0117\tT_eval 0.8387\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.32\n","9\tT_sample 8.6555\tT_update 2.3009\tT_eval 0.8485\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.27\n","10\tT_sample 8.5708\tT_update 2.1332\tT_eval 0.8342\ttrain_R_min 106.00\ttrain_R_max 200.00\ttrain_R_avg 188.81\teval_R_avg 9.43\n","11\tT_sample 8.8555\tT_update 3.1993\tT_eval 1.0734\ttrain_R_min 186.00\ttrain_R_max 200.00\ttrain_R_avg 199.06\teval_R_avg 9.39\n","12\tT_sample 6.5218\tT_update 1.6870\tT_eval 0.8553\ttrain_R_min 89.00\ttrain_R_max 200.00\ttrain_R_avg 164.24\teval_R_avg 9.25\n","13\tT_sample 7.6392\tT_update 1.8031\tT_eval 0.8556\ttrain_R_min 141.00\ttrain_R_max 200.00\ttrain_R_avg 185.25\teval_R_avg 9.36\n","14\tT_sample 8.2042\tT_update 1.9857\tT_eval 0.7963\ttrain_R_min 128.00\ttrain_R_max 200.00\ttrain_R_avg 189.56\teval_R_avg 9.27\n","15\tT_sample 8.6218\tT_update 3.1624\tT_eval 1.0995\ttrain_R_min 165.00\ttrain_R_max 200.00\ttrain_R_avg 190.62\teval_R_avg 9.34\n","16\tT_sample 8.5938\tT_update 2.4173\tT_eval 1.2654\ttrain_R_min 175.00\ttrain_R_max 200.00\ttrain_R_avg 197.25\teval_R_avg 9.33\n","17\tT_sample 9.1760\tT_update 1.9041\tT_eval 0.8320\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.33\n","18\tT_sample 8.6765\tT_update 2.0318\tT_eval 0.8679\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.40\n","19\tT_sample 8.6492\tT_update 2.3782\tT_eval 0.8210\ttrain_R_min 196.00\ttrain_R_max 200.00\ttrain_R_avg 199.75\teval_R_avg 9.30\n","20\tT_sample 8.5835\tT_update 3.2389\tT_eval 0.8889\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.37\n","21\tT_sample 8.5648\tT_update 2.4408\tT_eval 1.4179\ttrain_R_min 194.00\ttrain_R_max 200.00\ttrain_R_avg 199.62\teval_R_avg 9.31\n","22\tT_sample 9.1937\tT_update 1.9866\tT_eval 0.8288\ttrain_R_min 175.00\ttrain_R_max 200.00\ttrain_R_avg 198.06\teval_R_avg 9.43\n","23\tT_sample 8.5149\tT_update 1.9800\tT_eval 0.8274\ttrain_R_min 188.00\ttrain_R_max 200.00\ttrain_R_avg 199.25\teval_R_avg 9.35\n","24\tT_sample 7.5512\tT_update 3.0359\tT_eval 0.8059\ttrain_R_min 147.00\ttrain_R_max 200.00\ttrain_R_avg 196.69\teval_R_avg 9.26\n","25\tT_sample 8.6505\tT_update 3.2440\tT_eval 1.4094\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.36\n","26\tT_sample 8.9337\tT_update 2.0373\tT_eval 1.2876\ttrain_R_min 180.00\ttrain_R_max 200.00\ttrain_R_avg 198.75\teval_R_avg 9.46\n","27\tT_sample 8.5673\tT_update 1.9234\tT_eval 0.8319\ttrain_R_min 168.00\ttrain_R_max 200.00\ttrain_R_avg 198.00\teval_R_avg 9.35\n","28\tT_sample 8.6830\tT_update 1.9177\tT_eval 0.8250\ttrain_R_min 185.00\ttrain_R_max 200.00\ttrain_R_avg 199.06\teval_R_avg 9.46\n","29\tT_sample 9.1688\tT_update 3.0141\tT_eval 0.7912\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.39\n","30\tT_sample 8.6999\tT_update 3.1842\tT_eval 1.3058\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.32\n","31\tT_sample 8.9348\tT_update 2.0933\tT_eval 1.4009\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.31\n","32\tT_sample 9.1993\tT_update 1.9717\tT_eval 0.8208\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.38\n","33\tT_sample 8.6733\tT_update 1.9985\tT_eval 0.8808\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.27\n","34\tT_sample 8.8057\tT_update 2.2194\tT_eval 0.8290\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.37\n","35\tT_sample 8.7667\tT_update 3.3979\tT_eval 0.8106\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.39\n","36\tT_sample 8.6001\tT_update 2.8181\tT_eval 1.4626\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.35\n","37\tT_sample 9.1161\tT_update 2.0132\tT_eval 1.1998\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.35\n","38\tT_sample 8.6077\tT_update 2.0789\tT_eval 0.9709\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.50\n","39\tT_sample 8.7456\tT_update 2.1392\tT_eval 0.8350\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.45\n","40\tT_sample 8.5873\tT_update 3.0868\tT_eval 1.0289\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.31\n","41\tT_sample 8.5901\tT_update 2.3798\tT_eval 1.3293\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.38\n","42\tT_sample 9.1466\tT_update 1.9696\tT_eval 0.8410\ttrain_R_min 199.00\ttrain_R_max 200.00\ttrain_R_avg 199.94\teval_R_avg 9.37\n","43\tT_sample 8.6570\tT_update 2.1485\tT_eval 0.9844\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.43\n","44\tT_sample 8.5729\tT_update 2.1064\tT_eval 0.8200\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.27\n","45\tT_sample 7.9804\tT_update 3.0877\tT_eval 1.1612\ttrain_R_min 154.00\ttrain_R_max 200.00\ttrain_R_avg 195.12\teval_R_avg 9.36\n","46\tT_sample 8.6089\tT_update 2.4265\tT_eval 1.3200\ttrain_R_min 200.00\ttrain_R_max 200.00\ttrain_R_avg 200.00\teval_R_avg 9.32\n","47\tT_sample 9.4919\tT_update 1.9056\tT_eval 0.8457\ttrain_R_min 132.00\ttrain_R_max 200.00\ttrain_R_avg 192.75\teval_R_avg 9.33\n","48\tT_sample 8.6345\tT_update 2.0385\tT_eval 0.8841\ttrain_R_min 176.00\ttrain_R_max 200.00\ttrain_R_avg 198.50\teval_R_avg 9.32\n","49\tT_sample 7.1949\tT_update 3.0322\tT_eval 0.8242\ttrain_R_min 77.00\ttrain_R_max 200.00\ttrain_R_avg 187.81\teval_R_avg 9.33\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# Eval Main - CartPole-v0"],"metadata":{"id":"vYoMIafwoelp"}},{"cell_type":"code","source":["import argparse\n","\n","parser = argparse.ArgumentParser(description='PyTorch TRPO example')\n","parser.add_argument('--env-name', default=\"Hopper-v2\", metavar='G',\n","                    help='name of the environment to run')\n","parser.add_argument('--model-path', metavar='G', required=True,\n","                    help='path of pre-trained model')\n","parser.add_argument('--render', action='store_true', default=False,\n","                    help='render the environment')\n","parser.add_argument('--seed', type=int, default=1, metavar='N',\n","                    help='random seed (default: 1)')\n","parser.add_argument('--gpu-index', type=int, default=0, metavar='N')\n","parser.add_argument('--num-eval', type=int, default=1, metavar='N')\n","\n","args = parser.parse_args(args=[\n","    '--env-name', 'CartPole-v0',\n","    '--model-path', 'learned_models/CartPole-v0_trpo.p',\n","    '--seed', '1',\n","    '--gpu-index', '0',\n","    '--num-eval', '10'\n","])\n","\n","\n","dtype = torch.float64\n","torch.set_default_dtype(dtype)\n","device = torch.device('cuda', index=args.gpu_index) if torch.cuda.is_available() else torch.device('cpu')\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(args.gpu_index)\n","\n","\"\"\"environment\"\"\"\n","env = gym.make(args.env_name)\n","state_dim = env.observation_space.shape[0]\n","is_disc_action = len(env.action_space.shape) == 0\n","running_state = ZFilter((state_dim,), clip=5)\n","\n","\"\"\"seeding\"\"\"\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","env.seed(args.seed)\n","\n","\"\"\"define actor and critic\"\"\"\n","policy_net, value_net, running_state = pickle.load(open(args.model_path, \"rb\"))\n","policy_net.to(device)\n","value_net.to(device)\n","\n","\"\"\"create agent\"\"\"\n","agent = Agent(env, policy_net, device, running_state=running_state, num_threads=1)\n","mean_action = True  # In evaluation, there is no exploration of action, just use mean action.\n","\n","\n","\n","def main_eval():\n","    episode_rewards = []\n","\n","    for e in range(1, args.num_eval+1):\n","        done = False\n","        state = env.reset()\n","        if running_state is not None:\n","            state = running_state(state.squeeze())\n","        reward_episode = 0\n","\n","        while not done:\n","            state_var = tensor(state, dtype=dtype).unsqueeze(0).to(device)\n","            with torch.no_grad():\n","              if policy_net.is_disc_action:\n","                    # Discrete action takes the action with max probability\n","                    action_prob = policy_net(state_var).cpu().numpy()\n","                    action = np.argmax(action_prob)\n","              else:\n","                    # Discrete action takes the mean of action distribution\n","                    action_mean, _, _ = policy_net(state_var)\n","                    action = action_mean.cpu().numpy()\n","            next_state, reward, done, _ = env.step(action)\n","\n","            if running_state is not None:\n","                next_state = running_state(next_state.squeeze())\n","\n","            state = next_state\n","\n","\n","            if args.render:\n","                env.render()\n","            reward_episode += reward\n","\n","\n","        print(f\"Episode {e} Total Reward {reward_episode}\")\n","        episode_rewards.append(reward_episode)\n","\n","    \"\"\"clean up gpu memory\"\"\"\n","    torch.cuda.empty_cache()\n","\n","    env.close()\n","    print(f\"Number of Episodes {args.num_eval} Mean Reward {np.mean(episode_rewards)} Std Reward {np.std(episode_rewards)}\")\n","\n","    return episode_rewards\n","\n","main_eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"azHZIhKCodRv","executionInfo":{"status":"ok","timestamp":1721839532402,"user_tz":240,"elapsed":729,"user":{"displayName":"Bruce Li","userId":"04634146026403153182"}},"outputId":"dfeacc12-fb54-45ad-b229-38303872510a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n","  logger.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Episode 1 Total Reward 200.0\n","Episode 2 Total Reward 200.0\n","Episode 3 Total Reward 200.0\n","Episode 4 Total Reward 200.0\n","Episode 5 Total Reward 200.0\n","Episode 6 Total Reward 200.0\n","Episode 7 Total Reward 200.0\n","Episode 8 Total Reward 200.0\n","Episode 9 Total Reward 200.0\n","Episode 10 Total Reward 200.0\n","Number of Episodes 10 Mean Reward 200.0 Std Reward 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["[200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"GEkAFrl6hzy7"},"source":["# Conclusion\n"]},{"cell_type":"markdown","source":["In this tutorial, we have covered the TRPO algorithm. On top of the vanilla Policy Gradient (VPG) algorithm or Actor Critic (AC) algorithm, what distinguishes the TRPO algorithm from VPG and AC are:\n","\n","**Trust Region Stability:** TRPO uses a \"trust region\" to limit policy updates, ensuring stable training by maintaining the KL divergence within a predefined threshold.\n","\n","**Guaranteed Improvement**: TRPO offers theoretical guarantees of monotonic improvement, critical for applications where consistent progress is essential."],"metadata":{"id":"vrYVgq92mKmN"}}],"metadata":{"colab":{"gpuType":"T4","toc_visible":true,"provenance":[{"file_id":"1Y0q_cfpbJCEH-za1Bun1XoKOUsOr25de","timestamp":1721571604230},{"file_id":"1d5AIcPfCGQP-fnwZJdnzrCjBWmznZWG7","timestamp":1720907278670}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}